#
# Copyright 2021-2023 Aklivity Inc
#
# Licensed under the Aklivity Community License (the "License"); you may not use
# this file except in compliance with the License.  You may obtain a copy of the
# License at
#
#   https://www.aklivity.io/aklivity-community-license/
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OF ANY KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations under the License.
#

accept "zilla://streams/kafka0"
        option zilla:window 8192
        option zilla:transmission "duplex"

accepted

read zilla:begin.ext ${kafka:matchBeginEx()
                            .typeId(zilla:id("kafka"))
                            .merged()
                                .capabilities("PRODUCE_AND_FETCH")
                                .topic("mqtt-sessions")
                                .groupId("mqtt-clients")
                                .filter()
                                    .key("client-1#migrate")
                                    .headerNot("sender-id", "sender-1")
                                    .build()
                                .build()
                            .build()}

connected

read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#migrate")
                               .hashKey("client-1")
                               .header("sender-id", "sender-1")
                               .build()
                           .build()}
read zilla:data.empty

read closed
write close

accepted

read zilla:begin.ext ${kafka:matchBeginEx()
                               .typeId(zilla:id("kafka"))
                               .group()
                                   .groupId("client-1")
                                   .protocol("highlander")
                                   .timeout(1000)
                                   .build()
                               .build()}

connected

write advise zilla:flush ${kafka:flushEx()
                             .typeId(zilla:id("kafka"))
                             .group()
                                 .leaderId("consumer-1")
                                 .memberId("consumer-1")
                                 .members("consumer-1")
                                 .build()
                             .build()}
write flush

read zilla:data.empty

read advised zilla:flush

# On the session stream the heartbeat arrives (on the mqtt-sessions merged stream)
read await HEARTBEAT1_SENT

write advise zilla:flush ${kafka:flushEx()
                             .typeId(zilla:id("kafka"))
                             .group()
                                 .leaderId("consumer-1")
                                 .memberId("consumer-1")
                                 .members("consumer-1")
                                 .members("consumer-2")
                                 .build()
                             .build()}
write flush

# We've realised that we're the leader, but there's another member -> leave

read closed
write notify FIRST_CLIENT_LEFT
# On the session publish stream, send a heartbeat, that triggers the second connection to heartbeat on the group stream

write close

accepted

read zilla:begin.ext ${kafka:matchBeginEx()
                            .typeId(zilla:id("kafka"))
                            .merged()
                                .capabilities("PRODUCE_AND_FETCH")
                                .topic("mqtt-sessions")
                                .groupId("mqtt-clients")
                                .filter()
                                    .key("client-1")
                                    .build()
                                .filter()
                                    .key("client-1#migrate")
                                    .headerNot("sender-id", "sender-1")
                                    .build()
                                .build()
                            .build()}

connected

# will delivery cancellation signal for client-1
read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#will-signal")
                               .hashKey("client-1")
                               .header("type", "will-signal")
                               .build()
                           .build()}
read zilla:data.null

# session expiry cancellation signal for client-1
read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#expiry-signal")
                               .hashKey("client-1")
                               .header("type", "expiry-signal")
                               .build()
                           .build()}
read zilla:data.null

# session expire later signal for client-1
read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#expiry-signal")
                               .hashKey("client-1")
                               .header("type", "expiry-signal")
                               .build()
                           .build()}
read ${mqtt:sessionSignal()
           .expiry()
               .instanceId("zilla-1")
               .clientId("client-1")
               .delay(1000)
               .expireAt(-1)
               .build()
           .build()}

write advise zilla:flush

read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1")
                               .build()
                           .build()}

read ${mqtt:session()
               .subscription("sensor/one", 1)
               .build()}

write zilla:data.ext ${kafka:dataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1")
                               .build()
                           .build()}
write ${mqtt:session()
               .subscription("sensor/one", 1)
               .build()}
write flush

write zilla:data.ext ${kafka:dataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#migrate")
                               .hashKey("client-1")
                               .header("sender-id", "sender-1")
                               .build()
                           .build()}
write zilla:data.empty
write flush

#We've left the group -> send migrate
read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#migrate")
                               .hashKey("client-1")
                               .header("sender-id", "sender-1")
                               .build()
                           .build()}
read zilla:data.empty

# will signal for client-1, deliver at (now + delay)
read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#will-signal")
                               .hashKey("client-1")
                               .build()
                           .build()}
read ${mqtt:sessionSignal()
           .will()
               .instanceId("zilla-1")
               .clientId("client-1")
               .delay(0)
               .deliverAt(1000)
               .build()
           .build()}

read closed
write close

accepted

read zilla:begin.ext ${kafka:matchBeginEx()
                            .typeId(zilla:id("kafka"))
                            .merged()
                                .capabilities("FETCH_ONLY")
                                .topic("mqtt-messages")
                                .filter()
                                    .headers("zilla:filter")
                                        .sequence("sensor")
                                        .sequence("one")
                                        .build()
                                    .build()
                                .evaluation("EAGER")
                                .build()
                            .build()}

connected

read closed
write close


accepted

read zilla:begin.ext ${kafka:matchBeginEx()
                            .typeId(zilla:id("kafka"))
                            .merged()
                                .capabilities("PRODUCE_AND_FETCH")
                                .topic("mqtt-sessions")
                                .groupId("mqtt-clients")
                                .filter()
                                    .key("client-1#migrate")
                                    .headerNot("sender-id", "sender-1")
                                    .build()
                                .build()
                            .build()}

connected

read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#migrate")
                               .hashKey("client-1")
                               .header("sender-id", "sender-1")
                               .build()
                           .build()}
read zilla:data.empty

write notify HEARTBEAT1_SENT

read await FIRST_CLIENT_LEFT

#Migrate arrives from the first connection
write zilla:data.ext ${kafka:dataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#migrate")
                               .hashKey("client-1")
                               .header("sender-id", "sender-1")
                               .build()
                           .build()}
write zilla:data.empty

read closed
write close

accepted

read zilla:begin.ext ${kafka:matchBeginEx()
                               .typeId(zilla:id("kafka"))
                               .group()
                                   .groupId("client-1")
                                   .protocol("highlander")
                                   .timeout(1000)
                                   .build()
                               .build()}

connected

write advise zilla:flush ${kafka:flushEx()
                             .typeId(zilla:id("kafka"))
                             .group()
                                 .leaderId("consumer-1")
                                 .memberId("consumer-2")
                                 .members("consumer-1")
                                 .members("consumer-2")
                                 .build()
                             .build()}
write flush

read zilla:data.empty

# On the session publish stream, send a heartbeat
read advised zilla:flush


# Wait until I receive a data frame, that confirms that I'm the leader
# Once it's confirmed, I can send the CONNACK

write advise zilla:flush ${kafka:flushEx()
                             .typeId(zilla:id("kafka"))
                             .group()
                                 .leaderId("consumer-2")
                                 .memberId("consumer-2")
                                 .members("consumer-2")
                                 .build()
                             .build()}
write flush

read zilla:data.empty

accepted

read zilla:begin.ext ${kafka:matchBeginEx()
                            .typeId(zilla:id("kafka"))
                            .merged()
                                .capabilities("PRODUCE_AND_FETCH")
                                .topic("mqtt-sessions")
                                .groupId("mqtt-clients")
                                .filter()
                                    .key("client-1")
                                    .build()
                                .filter()
                                    .key("client-1#migrate")
                                    .headerNot("sender-id", "sender-1")
                                    .build()
                                .build()
                            .build()}

connected

# will delivery cancellation signal for client-1
read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#will-signal")
                               .hashKey("client-1")
                               .header("type", "will-signal")
                               .build()
                           .build()}
read zilla:data.null

# session expiry cancellation signal for client-1
read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#expiry-signal")
                               .hashKey("client-1")
                               .header("type", "expiry-signal")
                               .build()
                           .build()}
read zilla:data.null

# session expire later signal for client-1
read zilla:data.ext ${kafka:matchDataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1#expiry-signal")
                               .hashKey("client-1")
                               .header("type", "expiry-signal")
                               .build()
                           .build()}
read ${mqtt:sessionSignal()
           .expiry()
               .instanceId("zilla-1")
               .clientId("client-1")
               .delay(1000)
               .expireAt(-1)
               .build()
           .build()}

write zilla:data.ext ${kafka:dataEx()
                           .typeId(zilla:id("kafka"))
                           .merged()
                               .deferred(0)
                               .partition(-1, -1)
                               .key("client-1")
                               .build()
                           .build()}
write ${mqtt:session()
               .subscription("sensor/one", 1)
               .build()}
write flush

write advise zilla:flush


accepted

read zilla:begin.ext ${kafka:matchBeginEx()
                            .typeId(zilla:id("kafka"))
                            .merged()
                                .capabilities("FETCH_ONLY")
                                .topic("mqtt-messages")
                                .filter()
                                    .headers("zilla:filter")
                                        .sequence("sensor")
                                        .sequence("one")
                                        .build()
                                    .build()
                                .evaluation("EAGER")
                                .build()
                            .build()}

connected

write zilla:data.ext ${kafka:dataEx()
                            .typeId(zilla:id("kafka"))
                            .merged()
                                .timestamp(kafka:timestamp())
                                .filters(1)
                                .partition(0, 1, 2)
                                .progress(0, 2)
                                .progress(1, 1)
                                .key("sensor/one")
                                .header("zilla:filter", "sensor")
                                .header("zilla:filter", "one")
                                .header("zilla:local", "client-1")
                                .header("zilla:format", "TEXT")
                                .build()
                            .build()}

write "message"
write flush

